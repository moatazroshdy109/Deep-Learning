{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense, ReLU, Activation, Conv1D, Normalization, LayerNormalization, BatchNormalization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "class Powerlayer(tf.keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    super(Customdense, self).__init__()\n",
    "    self.normal = []\n",
    "  def build(self, input):\n",
    "    self.normal = np.var(input)+np.mean(input)*np.mean(input)\n",
    "  def call(self, input):\n",
    "    y = input/self.normal\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import backend\n",
    "from keras.engine import base_layer\n",
    "from keras.utils import tf_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "@keras_export(\"keras.activations.powernorm\")\n",
    "@tf.__internal__.dispatch.add_dispatch_support\n",
    "def powernorm(x, axis=-1):\n",
    "    if x.shape.rank > 1:\n",
    "        if isinstance(axis, int):\n",
    "            output = tf.nn.powernorm(x, axis=axis)\n",
    "        else:\n",
    "            # nn.softmax does not support tuple axis.\n",
    "            e = x\n",
    "            s = tf.reduce_sum(x*x, axis=axis, keepdims=True)/len(x)\n",
    "            output = e / s\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Cannot apply powernorm to a tensor that is 1D. \"\n",
    "            f\"Received input: {x}\"\n",
    "        )\n",
    "\n",
    "    # Cache the logits to use for crossentropy loss.\n",
    "    output._keras_logits = x\n",
    "    return output\n",
    "\n",
    "@keras_export('keras.layers.Fsolayer')\n",
    "class Fsolayer(base_layer.BaseRandomLayer):\n",
    "\n",
    "  def __init__(self, **kwargs):\n",
    "    super(Fsolayer, self).__init__( **kwargs)\n",
    "    self.supports_masking = True\n",
    "\n",
    "  def call(self, inputs, training=None):\n",
    "\n",
    "    def noised():\n",
    "      J_S_D=0.3     #%%% Jetter Standard Deviation\n",
    "      H_l=0.8      #%%%% pass loss factor\n",
    "      a=0.1        #%%% Radius\n",
    "      R=0.5         #%%% responsitivity\n",
    "      L=2000        #%%%% distance in m\n",
    "      theta=2.5/1000 #%%% divergence angle\n",
    "      W_z=theta*L     #%%% Beam radius\n",
    "      wl=1550/1000000000   #%%%% wavelength in nm\t\n",
    "      ha = []\n",
    "      alpha = 4.505303125003634\n",
    "      beta  = 2.714091563350723\n",
    "      elements = 1\t\n",
    "      temp1 = random.gammavariate(alpha, 1/alpha)\n",
    "      temp2 = random.gammavariate(beta, 1/beta)\n",
    "      ha = temp1*temp2\n",
    "      W_z_eq = 5.001047351093471\n",
    "      A_o = 6.774000000000000e-04\n",
    "      r_pdf = np.random.rayleigh(J_S_D,elements)\n",
    "      r_pdf = list(r_pdf)\n",
    "      hp = A_o*np.exp(-np.multiply(r_pdf,r_pdf)*2/W_z_eq)\n",
    "      return inputs*ha*hp\n",
    "\n",
    "    return backend.in_train_phase(noised, inputs, training=training)\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {}\n",
    "    base_config = super(Fsolayer, self).get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "  @tf_utils.shape_type_conversion\n",
    "  def compute_output_shape(self, input_shape):\n",
    "    return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "#Generate random numbers between 0 and 15 for training data\n",
    "symbols = np.random.randint(0,16,100000)\n",
    "X_train = np.zeros((symbols.size, symbols.max()+1))\n",
    "X_train[np.arange(symbols.size),symbols] = 1\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate random numbers between 0 and 15 for test data\n",
    "symbols = np.random.randint(0,16,10000)\n",
    "X_test = np.zeros((symbols.size, symbols.max()+1))\n",
    "X_test[np.arange(symbols.size),symbols] = 1\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Noise and Power\n",
    "R=4/7;\n",
    "Eb_No_training=7; ## dB\n",
    "Eb_No_training_ratio=10**(Eb_No_training/10);\n",
    "stddev=(2*R*Eb_No_training_ratio)**(-0.5);\n",
    "N_S_D=1e-07; \n",
    "## Power\n",
    "Pdb = np.linspace(-25,25,51);   #dbm\n",
    "P_m = 10**(Pdb/10);   #mW\n",
    "P = P_m/1000;         #W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 16])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################### Autoencoder Parts\n",
    "inputs= X_test.shape[1]\n",
    "#define the encoder \n",
    "encoder_input = Input(shape=(inputs,))\n",
    "encoder_layer = Dense(inputs, activation=\"relu\")(encoder_input)\n",
    "encoder_layer = Dense(7, activation=\"linear\")(encoder_layer)\n",
    "encoder_output = BatchNormalization()(encoder_layer)\n",
    "# FSO channel\n",
    "fso=Fsolayer()(encoder_output)\n",
    "channel_output=tf.keras.layers.GaussianNoise(N_S_D)(fso) \n",
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the decoder \n",
    "decoder= Dense(inputs, activation=\"relu\")(channel_output)\n",
    "from tensorflow import expand_dims, squeeze\n",
    "layer = expand_dims(decoder, 2)\n",
    "decoder = Conv1D(filters=16, kernel_size=1,\n",
    "                          strides=1, padding='valid',\n",
    "                          data_format='channels_first')(layer)\n",
    "layer2 = squeeze(decoder,[2])    ## to remove the last dim                      \n",
    "decoder_output = Dense(inputs, activation=\"softmax\")(layer2)\n",
    "\n",
    "# define the autoencoder\n",
    "\n",
    "autoencoder=Model(inputs=encoder_input, outputs=decoder_output)\n",
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encoder side\n",
    "encoder=Model(inputs=encoder_input, outputs=encoder_output)\n",
    "#decoder side \n",
    "decoder=Model(inputs=channel_output, outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model_3/conv1d_1/Conv1D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\moata\\AppData\\Local\\Temp\\ipykernel_11552\\2739234073.py\", line 2, in <cell line: 2>\n      history=autoencoder.fit(X_train,X_train,epochs=10, validation_data=(X_test,X_test),batch_size=1000)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model_3/conv1d_1/Conv1D/Conv2DBackpropInput'\nConv2DCustomBackpropInputOp only supports NHWC.\n\t [[{{node gradient_tape/model_3/conv1d_1/Conv1D/Conv2DBackpropInput}}]] [Op:__inference_train_function_3565]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11552\\2739234073.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#autoencoder.save(\"functional_encoder.h5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model_3/conv1d_1/Conv1D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\moata\\AppData\\Local\\Temp\\ipykernel_11552\\2739234073.py\", line 2, in <cell line: 2>\n      history=autoencoder.fit(X_train,X_train,epochs=10, validation_data=(X_test,X_test),batch_size=1000)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"c:\\Users\\moata\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model_3/conv1d_1/Conv1D/Conv2DBackpropInput'\nConv2DCustomBackpropInputOp only supports NHWC.\n\t [[{{node gradient_tape/model_3/conv1d_1/Conv1D/Conv2DBackpropInput}}]] [Op:__inference_train_function_3565]"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "history=autoencoder.fit(X_train,X_train,epochs=10, validation_data=(X_test,X_test),batch_size=1000)\n",
    "#autoencoder.save(\"functional_encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7)                28        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " fsolayer (Fsolayer)         (None, 7)                 0         \n",
      "                                                                 \n",
      " gaussian_noise (GaussianNoi  (None, 7)                0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                128       \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 16, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 16, 1)             272       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (None, 16)               0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,091\n",
      "Trainable params: 1,077\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7)                28        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 419\n",
      "Trainable params: 405\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 7)]               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                128       \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 16, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 16, 1)             272       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (None, 16)               0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 672\n",
      "Trainable params: 672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 999us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.053214964"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "encodedsymbols=encoder.predict(X_test)\n",
    "# noise = np.random.normal(0,stddev,[10000,7])\n",
    "# noisy=encodedsymbols+noise\n",
    "# decoded_symbols=decoder.predict(noisy)\n",
    "# #convert the probability to hot vector\n",
    "# a=decoded_symbols\n",
    "# idx = np.argmax(a, axis=-1)\n",
    "# a = np.zeros( a.shape )\n",
    "# a[ np.arange(a.shape[0]), idx] = 1\n",
    "rms = np.sqrt(np.mean(encodedsymbols**2))\n",
    "rms*rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8120\\1023962799.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m######==============================>plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "######==============================>plotting\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1, len(acc)+1)\n",
    "plt.plot(epochs, acc, 'k--', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'k--', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate random numbers between 0 and 15 for BER calculations\n",
    "test_size=1000000;\n",
    "symbols = np.random.randint(0,16,test_size)\n",
    "X_test = np.zeros((symbols.size, symbols.max()+1))\n",
    "X_test[np.arange(symbols.size),symbols] = 1\n",
    "\n",
    "#generating a E/N vector\n",
    "R=4/7;\n",
    "num_steps=26\n",
    "Eb_No=np.linspace(-4,8,num_steps); ## dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BER=np.zeros(num_steps)\n",
    "for i in range(len(Eb_No)):\n",
    "  Eb_No_ratio=10**(Eb_No[i]/10);\n",
    "  stddev=(2*R*Eb_No_ratio)**(-0.5);\n",
    "  encodedsymbols=encoder.predict(X_test)\n",
    "  noise = np.random.normal(0,stddev,[test_size,7])\n",
    "  noisy=encodedsymbols+noise\n",
    "  a=decoder.predict(noisy)\n",
    "  idx = np.argmax(a, axis=-1)\n",
    "  a = np.zeros( a.shape )\n",
    "  a[ np.arange(a.shape[0]), idx] = 1\n",
    "  recovered_symbols=np.argmax(a, axis=1)\n",
    "  errors=np.count_nonzero(recovered_symbols-symbols)\n",
    "  BER[i]=errors/len(symbols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.semilogy(Eb_No, BER, 'k--')\n",
    "plt.title('Block Error Rate')\n",
    "plt.xlabel('E_b/N_o')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customdense(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_units, activation = \"relu\"):\n",
    "    super(Customdense, self).__init__()\n",
    "    self.num_units = num_units\n",
    "    self.activation = Activation(activation)\n",
    "  def build(self, input_shape):\n",
    "    self.weight = self.add_weight(shape = [input_shape[-1], self.num_units])\n",
    "    self.bias = self.add_weight(shape =[self.num_units])\n",
    "  def call(self, input):\n",
    "    y = tf.matmul(input, self.weight) + self.bias\n",
    "    y = self.activation(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.constant([5, 1, 2, 4])\n",
    "print(tf.reduce_max(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import backend\n",
    "from keras.engine import base_layer\n",
    "from keras.utils import tf_utils\n",
    "import tensorflow.compat.v2 as tf\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "@keras_export(\"keras.activations.powernorm\")\n",
    "@tf.__internal__.dispatch.add_dispatch_support\n",
    "def powernorm(x, axis=-1):\n",
    "    if x.shape.rank > 1:\n",
    "        if isinstance(axis, int):\n",
    "            output = tf.nn.powernorm(x, axis=axis)\n",
    "        else:\n",
    "            # nn.softmax does not support tuple axis.\n",
    "            e = x\n",
    "            s = tf.reduce_sum(x*x, axis=axis, keepdims=True)/len(x)\n",
    "            output = e / s\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Cannot apply softmax to a tensor that is 1D. \"\n",
    "            f\"Received input: {x}\"\n",
    "        )\n",
    "\n",
    "    # Cache the logits to use for crossentropy loss.\n",
    "    output._keras_logits = x\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1412fab97f5cd6b795ba756da771fd7730ca0dca44164ea9fd0fcc4b6c221237"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
